{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dineshuthayakumarkissflow/kf-custom-components/blob/main/Attachment_Folder_Organisation.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2ZXv-Pg5KhBX"
      },
      "outputs": [],
      "source": [
        "!pip install requests requests-aws4auth boto3"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# **Attachment Processing Logic**\n"
      ],
      "metadata": {
        "id": "H7z14xyDWgdP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from re import split\n",
        "import csv\n",
        "import boto3\n",
        "import requests\n",
        "from google.colab import userdata\n",
        "\n",
        "attachment_columns=split(',',userdata.get('list-of-fields'))\n",
        "aws_access_key = userdata.get(\"Aws-Access-Key\")\n",
        "aws_secret_key = userdata.get(\"Aws-Secret-Key\")\n",
        "aws_bucket_name = userdata.get(\"Aws-Bucket-Name\")\n",
        "aws_region = userdata.get('Aws-Region')\n",
        "\n",
        "# ---------- Data Classes ----------\n",
        "\n",
        "class AttachmentFile:\n",
        "    def __init__(self, id, filename, location):\n",
        "        self.id = id\n",
        "        self.filename = filename\n",
        "        self.location = location\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"AttachmentFile(id={self.id}, filename='{self.filename}', location='{self.location}')\"\n",
        "\n",
        "class ProcessField:\n",
        "    def __init__(self, field_schema_name, attachments):\n",
        "        self.field_schema_name = field_schema_name\n",
        "        self.attachments = attachments  # List of AttachmentFile\n",
        "\n",
        "    def __repr__(self):\n",
        "        return f\"ProcessField(field_schema_name='{self.field_schema_name}', attachments={self.attachments})\"\n",
        "\n",
        "class Process:\n",
        "    def __init__(self, id, name, request_number, requester_name):\n",
        "        self.id = id\n",
        "        self.name = name\n",
        "        self.request_number = request_number\n",
        "        self.requester_name = requester_name\n",
        "        self.fields = []  # List of ProcessField\n",
        "\n",
        "    def __repr__(self):\n",
        "        return (\n",
        "            f\"Process(id={self.id!r}, name={self.name!r}, request_number={self.request_number}, \"\n",
        "            f\"requester_name={self.requester_name!r}, fields={self.fields})\"\n",
        "        )"
      ],
      "metadata": {
        "id": "ma2kSZqHWCTD"
      },
      "execution_count": 22,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Kissflow API Client Configuration ----------\n",
        "kf_sub_domain = userdata.get('kf-sub-domain')\n",
        "kf_api_version = userdata.get('kf-api-version')\n",
        "kf_accountid = userdata.get('kf-accountid')\n",
        "kf_process_name = userdata.get('kf-process-name')\n",
        "\n",
        "if kf_api_version == \"2\":\n",
        "    kissflow_api_headers = {\n",
        "        \"X-Access-Key-Id\": userdata.get(\"X-Access-Key-Id\"),\n",
        "        \"X-Access-Key-Secret\": userdata.get(\"X-Access-Key-Secret\")\n",
        "    }\n",
        "else:\n",
        "    kissflow_api_headers = {\n",
        "      \"X-Api-Key\": userdata.get(\"X-Api-Key\"),\n",
        "    }"
      ],
      "metadata": {
        "id": "959qt8IKWC7p"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Fetch all process items from Kissflow API ----------\n",
        "def kf_fetch_specific_page(kf_page_no, kf_page_size):\n",
        "    kissflow_api_url = f\"https://{kf_sub_domain}.kissflow.com/process/{kf_api_version}/{kf_accountid}/admin/{kf_process_name}/item\"\n",
        "    kissflow_api_params = {\n",
        "      \"page_number\": kf_page_no,\n",
        "      \"page_size\": kf_page_size,\n",
        "      \"apply_preference\": False\n",
        "    }\n",
        "\n",
        "    response = requests.get(kissflow_api_url, headers=kissflow_api_headers, params=kissflow_api_params)\n",
        "    if response.status_code == 200:\n",
        "        return response.json().get(\"Data\", [])\n",
        "    else:\n",
        "        print(\"Error fetching Kissflow data:\", response.text)\n",
        "        return []"
      ],
      "metadata": {
        "id": "7ZkK3u_5bXlQ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def kf_fetch_all_pages():\n",
        "    all_data = []\n",
        "    kissflow_api_url = f\"https://{kf_sub_domain}.kissflow.com/process/{kf_api_version}/{kf_accountid}/admin/{kf_process_name}/item\"\n",
        "    kf_page_number = 1\n",
        "    while True:\n",
        "        kissflow_api_params = {\n",
        "            \"page_number\": kf_page_number,\n",
        "            \"page_size\": int(userdata.get('kf-page-size')),\n",
        "            \"apply_preference\": False\n",
        "        }\n",
        "\n",
        "        response = requests.get(kissflow_api_url, headers=kissflow_api_headers, params=kissflow_api_params)\n",
        "\n",
        "        if response.status_code != 200:\n",
        "            print(f\"[ERROR] Failed to fetch page {kf_page_number}: {response.text}\")\n",
        "            break\n",
        "\n",
        "        data = response.json().get(\"Data\", [])\n",
        "\n",
        "        if not data:\n",
        "            print(f\"[INFO] No more data after page {kf_page_number}\")\n",
        "            break\n",
        "\n",
        "        print(f\"[DEBUG] Retrieved {len(data)} items from page {kf_page_number}\")\n",
        "        all_data.extend(data)\n",
        "\n",
        "        kf_page_number += 1  # Move to the next page\n",
        "\n",
        "    print(f\"[INFO] Total items retrieved: {len(all_data)}\")\n",
        "    return all_data\n",
        "kf_process_items = kf_fetch_all_pages()"
      ],
      "metadata": {
        "id": "S6BEghDyWR8m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Fetch specific process item from Kissflow API for testing purposes ----------\n",
        "def fetch_specific_process_item_from_kissflow(kf_process_item_instanceid):\n",
        "    kissflow_api_url = f\"https://{kf_sub_domain}.kissflow.com/process/{kf_api_version}/{kf_accountid}/admin/{kf_process_name}/{kf_process_item_instanceid}\"\n",
        "    kissflow_api_params = {\n",
        "      \"apply_preference\": False\n",
        "    }\n",
        "\n",
        "    response = requests.get(kissflow_api_url, headers=kissflow_api_headers, params=kissflow_api_params)\n",
        "    if response.status_code == 200:\n",
        "        return response.json()\n",
        "    else:\n",
        "        print(\"Error fetching Kissflow data:\", response.text)\n",
        "        return None"
      ],
      "metadata": {
        "id": "WibVZ-4Zu3el"
      },
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Amazon S3 Bucket Service Client ----------\n",
        "def print_to_file(attachments):\n",
        "    csv_filename = \"attachments.csv\"\n",
        "    with open(csv_filename, mode='w', newline='', encoding='utf-8') as csv_file:\n",
        "        writer = csv.writer(csv_file)\n",
        "        writer.writerow([\"ID\", \"Filename\", \"Location\"])  # Header\n",
        "        for attachment in attachments:\n",
        "            writer.writerow([attachment.id, attachment.filename, attachment.location])\n",
        "\n",
        "def collect_attachment_files():\n",
        "    s3 = boto3.client(\n",
        "    's3',\n",
        "    aws_access_key_id=userdata.get(\"Aws-Access-Key\"),\n",
        "    aws_secret_access_key=userdata.get(\"Aws-Secret-Key\"),\n",
        "    region_name=userdata.get('Aws-Region')\n",
        "    )\n",
        "    attachments = []\n",
        "    paginator = s3.get_paginator('list_objects_v2')\n",
        "    pages = paginator.paginate(Bucket=userdata.get(\"Aws-Bucket-Name\"), Prefix=userdata.get(\"aws-s3-prefix\"), PaginationConfig={'PageSize': 500})\n",
        "\n",
        "    for page in pages:\n",
        "        if 'Contents' not in page:\n",
        "            continue\n",
        "        for obj in page['Contents']:\n",
        "            key = obj['Key']\n",
        "            parts = key.split('/')\n",
        "            #print(len(parts))\n",
        "            if key.endswith('/') or len(parts) <= 4:\n",
        "                continue  # skip folder markers\n",
        "\n",
        "            #print(parts)\n",
        "            attachment_id = parts[3]\n",
        "            filename = parts[4]\n",
        "\n",
        "            attachment = AttachmentFile(\n",
        "                id=attachment_id,\n",
        "                filename=filename,\n",
        "                location=key\n",
        "            )\n",
        "            attachments.append(attachment)\n",
        "\n",
        "    return attachments"
      ],
      "metadata": {
        "id": "OF3jmkO62j3l"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Map S3 Attachment to Kissflow Process Items ----------\n",
        "def map_attachments_to_processes(attachment_files, kissflow_process_items):\n",
        "    matched_processes = []\n",
        "\n",
        "    for kissflow_process_item in kissflow_process_items:\n",
        "        process_id = kissflow_process_item[\"_id\"]\n",
        "        process_name = kissflow_process_item[\"Name\"]\n",
        "        request_number = kissflow_process_item.get(\"Purchase_Request_Number\", \"NA\")\n",
        "        requester_name = kissflow_process_item.get(\"_created_by\", \"NA\").get(\"Name\")\n",
        "\n",
        "        process = Process(\n",
        "                id=process_id,\n",
        "                name=process_name,\n",
        "                request_number=request_number,\n",
        "                requester_name=requester_name\n",
        "        )\n",
        "        matched_processes.append(process)\n",
        "\n",
        "        for attachment_column in attachment_columns:\n",
        "            if(kissflow_process_item.get(attachment_column,None)):\n",
        "                for attachment_column_details in kissflow_process_item[attachment_column]:\n",
        "                    for file in attachment_files:\n",
        "                        if file.id == attachment_column_details['id']:\n",
        "                            process.fields.append(ProcessField(\n",
        "                                field_schema_name=attachment_column,\n",
        "                                attachments=[file]\n",
        "                            ))\n",
        "    return matched_processes"
      ],
      "metadata": {
        "id": "_QGSZLWXWXkw"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Analyse mapping output for testing purpose ----------\n",
        "aws_attachment_files = collect_attachment_files()\n",
        "print_to_file(aws_attachment_files)\n",
        "kissflow_process_items = kf_fetch_all_pages()\n",
        "print(kissflow_process_items)\n",
        "mapped_processes = map_attachments_to_processes(aws_attachment_files, kissflow_process_items)\n",
        "\n",
        "for mapped_process in mapped_processes:\n",
        "    for mapped_field in mapped_process.fields:\n",
        "        for mapped_attachment in mapped_field.attachments:\n",
        "            print(mapped_process.id, '\\t', mapped_field.field_schema_name, '\\t', mapped_attachment.filename)\n",
        "\n",
        "kissflow_process_items"
      ],
      "metadata": {
        "id": "-tPk6cEr4QF9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Copy files to Amazon S3 Bucket Destination Folder ----------\n",
        "def copy_files_to_destination(processes):\n",
        "    s3 = boto3.client(\n",
        "    's3',\n",
        "    aws_access_key_id=userdata.get(\"Aws-Access-Key\"),\n",
        "    aws_secret_access_key=userdata.get(\"Aws-Secret-Key\"),\n",
        "    region_name=userdata.get('Aws-Region')\n",
        "    )\n",
        "\n",
        "    for process in processes:\n",
        "        for field in process.fields:\n",
        "            for attachment in field.attachments:\n",
        "                destination_key = (\n",
        "                    f\"/Backup/{kf_process_name}/{process.request_number} - {process.requester_name} - {process.id}/\"\n",
        "                    f\"{field.field_schema_name}/\"\n",
        "                    f\"Attachment - {attachment.id}/\"\n",
        "                    f\"{attachment.filename}\"\n",
        "                )\n",
        "                print(f\"Copying {attachment.location} → {destination_key}\")\n",
        "                try:\n",
        "                    s3.copy_object(\n",
        "                    Bucket=aws_bucket_name,\n",
        "                    CopySource={\"Bucket\": aws_bucket_name, \"Key\": attachment.location},\n",
        "                    Key=destination_key\n",
        "                )\n",
        "                except Exception as e:\n",
        "                    print({kf_process_name}/{process.request_number} - {process.requester_name} - {process.id})\n",
        "                    print(f\"An error occurred: {e}\")\n",
        ""
      ],
      "metadata": {
        "id": "uhM4EQHhWa7V"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- MAIN EXECUTION ----------\n",
        "aws_attachment_files = collect_attachment_files()\n",
        "print(f\"Finished getting AWS S3 Attachment Dump\")\n",
        "kissflow_process_items = kf_fetch_all_pages()\n",
        "print(f\"Finished getting {kf_process_name}!\")\n",
        "mapped_processes = map_attachments_to_processes(aws_attachment_files, kissflow_process_items)\n",
        "copy_files_to_destination(mapped_processes)"
      ],
      "metadata": {
        "id": "JiyG0EP6WdxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# ---------- Test Execution ----------\n",
        "aws_attachment_files = collect_attachment_files()\n",
        "print(aws_attachment_files[0])\n",
        "kissflow_process_items = [fetch_specific_process_item_from_kissflow(\"PkjtOgJ9DMLTr\")]\n",
        "mapped_processes = map_attachments_to_processes(aws_attachment_files, kissflow_process_items)\n",
        "copy_files_to_destination(mapped_processes)"
      ],
      "metadata": {
        "id": "082PenK0gBj_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s3 = boto3.client(\n",
        "    's3',\n",
        "    aws_access_key_id=aws_access_key,\n",
        "    aws_secret_access_key=aws_secret_key,\n",
        "    region_name=aws_region\n",
        "    )\n",
        "paginator = s3.get_paginator('list_objects_v2')\n",
        "pages = paginator.paginate(Bucket=aws_bucket_name, Prefix=\"/Backup\", PaginationConfig={'PageSize': 500})\n",
        "\n",
        "\n",
        "count = 0\n",
        "for page in pages:\n",
        "    if 'Contents' not in page:\n",
        "        continue\n",
        "    for obj in page['Contents']:\n",
        "        key = obj['Key']\n",
        "        parts = key.split('/')\n",
        "        #print(len(parts))\n",
        "        if key.endswith('/') or len(parts) <= 4:\n",
        "            continue  # skip folder markers\n",
        "        count += 1\n",
        "        #print(key)\n",
        "print(count)"
      ],
      "metadata": {
        "id": "hC-NYGdNed8V",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e1618335-a314-4731-c2cb-a0cfa6fbaeb9"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "25727\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# AWS S3 Bucket Snapshot to CSV"
      ],
      "metadata": {
        "id": "75GTXRMIXU4I"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "attachment_file = collect_attachment_files()\n",
        "print_to_file(attachment_file)"
      ],
      "metadata": {
        "id": "vVkaOSL9Xdeq"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}